{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741147714507,
     "user": {
      "displayName": "Hiếu NT",
      "userId": "17377350580696622026"
     },
     "user_tz": -420
    },
    "id": "SUJeyB7WTvcJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from src.dataset import VSLR_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1741147718471,
     "user": {
      "displayName": "Hiếu NT",
      "userId": "17377350580696622026"
     },
     "user_tz": -420
    },
    "id": "2wrtMrZMTvcK"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    data_path = \"dataset/alphabet\"\n",
    "    image_size = 224\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001\n",
    "    tensorboard_dir = \"tensorboard\"\n",
    "    checkpoint_dir = \"trained_models\"\n",
    "    checkpoint = None\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741147719939,
     "user": {
      "displayName": "Hiếu NT",
      "userId": "17377350580696622026"
     },
     "user_tz": -420
    },
    "id": "_gDj67E-ew6d"
   },
   "outputs": [],
   "source": [
    "os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(args.tensorboard_dir, exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(args.tensorboard_dir)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((args.image_size, args.image_size), antialias=True),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1741147724065,
     "user": {
      "displayName": "Hiếu NT",
      "userId": "17377350580696622026"
     },
     "user_tz": -420
    },
    "id": "7PF89Zhqeygt",
    "outputId": "8580f014-746f-400f-f57c-04d01e4fc304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4160 images\n",
      "Validation set: 520 images\n",
      "Test set: 520 images\n"
     ]
    }
   ],
   "source": [
    "train_set = VSLR_Dataset(args.data_path, transform=transform, mode=\"train\")\n",
    "val_set = VSLR_Dataset(args.data_path, transform=transform, mode=\"val\")\n",
    "test_set = VSLR_Dataset(args.data_path, transform=transform, mode=\"test\")\n",
    "\n",
    "print(f\"Training set: {len(train_set)} images\")\n",
    "print(f\"Validation set: {len(val_set)} images\")\n",
    "print(f\"Test set: {len(test_set)} images\")\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaRBDqE9TvcK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|\u001b[36m██████████\u001b[0m| 130/130 [17:10<00:00,  7.93s/it, loss=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Accuracy: 0.9885, Val Loss: 0.0624\n",
      "=> New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|\u001b[36m██████████\u001b[0m| 130/130 [18:40<00:00,  8.62s/it, loss=0.0847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Accuracy: 1.0000, Val Loss: 0.0016\n",
      "=> New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  65%|\u001b[36m██████▌   \u001b[0m| 85/130 [14:00<07:26,  9.92s/it, loss=0.00865]"
     ]
    }
   ],
   "source": [
    "num_class = train_set.num_class\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_class)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start_epoch = 0\n",
    "best_acc = 0.0\n",
    "\n",
    "if args.checkpoint and os.path.isfile(args.checkpoint):\n",
    "    checkpoint = torch.load(args.checkpoint)\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    best_acc = checkpoint[\"best_acc\"]\n",
    "    model.load_state_dict(checkpoint[\"model_params\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    print(f\"Loaded checkpoint: {args.checkpoint}\")\n",
    "\n",
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{args.num_epochs}\", colour=\"cyan\")\n",
    "\n",
    "    for images, labels in train_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_bar.set_postfix(loss=np.mean(train_losses))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_preds.extend(preds.tolist())\n",
    "\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    val_loss = np.mean(val_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Val Accuracy: {val_acc:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    writer.add_scalar(\"Val/Accuracy\", val_acc, epoch)\n",
    "    writer.add_scalar(\"Val/Loss\", val_loss, epoch)\n",
    "\n",
    "    # Save latest model\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"best_acc\": best_acc,\n",
    "        \"model_params\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(args.checkpoint_dir, \"last.pt\"))\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(checkpoint, os.path.join(args.checkpoint_dir, \"best.pt\"))\n",
    "        print(\"=> New best model saved!\")\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
